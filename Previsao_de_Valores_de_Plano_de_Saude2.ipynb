{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Previsao de Valores de Plano de Saude.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4t0J3c8uyki"
      },
      "source": [
        "#Carregando pacotes\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import pearsonr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy.stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PCJVT0_wtCF"
      },
      "source": [
        "dados=pd.read_csv(\"dfPrecoMensal_AnoMes.csv\") #dados que o Marcelo mandou por e-mail"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQrJltzGzLH1"
      },
      "source": [
        "dados.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyjpr59dzNSU"
      },
      "source": [
        "df = dados.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RedJ9JTNzQyu"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwJ-xcBp3Rm1"
      },
      "source": [
        "#dividindo ano_mes em 2 colunas\n",
        "df[['ano', 'mes']] = df['ano_mes'].str.split('-', 1, expand=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wrIOFyJwx2g"
      },
      "source": [
        "#OUTLIERS\n",
        "import numpy as np\n",
        "  \n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "sns.boxplot(x=df['mensalidade'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcNHeO5XxTZD"
      },
      "source": [
        "#criando z-score para remocao de outliers\n",
        "df=dados\n",
        "df[\"z\"]=np.abs(stats.zscore(df['mensalidade']))\n",
        "print(df[\"z\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHSiC5Vm3eNn"
      },
      "source": [
        "#Removendo outliers\n",
        "df_filtrado=df[(df[\"z\"] < 3)]\n",
        "df_filtrado=df_filtrado[(df_filtrado[\"mensalidade\"] < 900)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DM18uDS3rm4"
      },
      "source": [
        "#Verificando Outliers\n",
        "#OUTLIERS\n",
        "import numpy as np\n",
        "  \n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "sns.boxplot(x=df_filtrado['mensalidade'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N75qaXzO39qb"
      },
      "source": [
        "#apalicando o log\n",
        "df_filtrado[\"logy\"]=np.log(df_filtrado[\"mensalidade\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_bW2P7t5_3L"
      },
      "source": [
        "df_filtrado[\"logy\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2KGpWKy4B-x"
      },
      "source": [
        "#OUTLIERS\n",
        "import numpy as np\n",
        "  \n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "sns.boxplot(x=df_filtrado['logy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6KmsmAFwqNt"
      },
      "source": [
        "#OUTLIERS\n",
        "import numpy as np\n",
        "  \n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "sns.boxplot(x=df_filtrado['mensalidade'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNlusvMSxNSA"
      },
      "source": [
        "df_filtrado[\"logy\"]=np.log(df_filtrado[\"mensalidade\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0sIZ0YHxNxi"
      },
      "source": [
        "#Removendo outliers\n",
        "df_filtrado=df[(df[\"z\"] < 3)]\n",
        "df_filtrado=df_filtrado[(df_filtrado[\"mensalidade\"] < 850)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JkhL4TIzQ-i"
      },
      "source": [
        "#df_filtrado=df_filtrado[(df_filtrado[\"logy\"] > 3.5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmFXrW2G4SZJ"
      },
      "source": [
        "#Checando mais outliers\n",
        "#OUTLIERS\n",
        "import numpy as np\n",
        "  \n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "sns.boxplot(x=df_filtrado['logy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oqt9agsWyQEX"
      },
      "source": [
        "#Checando mais outliers\n",
        "#OUTLIERS\n",
        "import numpy as np\n",
        "  \n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "sns.boxplot(x=df_filtrado['z'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4r4w4Ll2Nfg"
      },
      "source": [
        "df_filtrado[\"logy\"]=np.log(df_filtrado[\"mensalidade\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R94BMU9s5A27"
      },
      "source": [
        "data=df_filtrado"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf3BfboCvd6F"
      },
      "source": [
        "#dividindo ano_mes em 2 colunas\n",
        "data[['ano', 'mes']] = data['ano_mes'].str.split('-', 1, expand=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWpLpDSWvPZm"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aA-2pEo72Xxu"
      },
      "source": [
        "df_filtrado[\"ano\"]=df_filtrado[\"ano\"].astype('int64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qJgN92W2vvo"
      },
      "source": [
        "df_filtrado.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7QwxMH42Tko"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_GVpSjk5EiV"
      },
      "source": [
        "#Tranformando para dummies e removendo variaveis redundantes\n",
        "data=df_filtrado\n",
        "cat_vars=[\"ano\",\"mes\",'contratacao','segmentacao','in_obstetricia','abrangencia','fator','acomodacao','internacao',\"cd_faixa_etaria\",\"nm_regiao\"]\n",
        "for var in cat_vars:\n",
        "    cat_list='var'+'_'+var\n",
        "    cat_list = pd.get_dummies(data[var], prefix=var)\n",
        "    data1=data.join(cat_list)\n",
        "    data=data1\n",
        "cat_vars=[\"ano\",\"mes\",'contratacao','segmentacao','in_obstetricia','abrangencia','fator','acomodacao','internacao',\"cd_faixa_etaria\",\"nm_regiao\"]\n",
        "data_vars=data.columns.values.tolist()\n",
        "to_keep=[i for i in data_vars if i not in cat_vars]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4quWyMec5Vex"
      },
      "source": [
        "data_final=data[to_keep]\n",
        "data_final.columns.values\n",
        "del data_final[\"in_obstetricia_0\"]\n",
        "del data_final[\"contratacao_Coletivo por ades√£o\"]\n",
        "del data_final[\"ano_mes\"]\n",
        "del data_final[\"z\"]\n",
        "del data_final[\"mensalidade\"]\n",
        "del data_final[\"tipo\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pv2VUTkO4rqK"
      },
      "source": [
        "# Import library for VIF\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def calc_vif(X):\n",
        "\n",
        "    # Calculating VIF\n",
        "    vif = pd.DataFrame()\n",
        "    vif[\"variables\"] = X.columns\n",
        "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "    return(vif)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqcSimsS9f5e"
      },
      "source": [
        "#Gerando uma amostra\n",
        "data_final2=data_final.sample(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHyBMVjf9q0l"
      },
      "source": [
        "#separando em variaveis target e preditoras\n",
        "x=data_final2.drop(\"logy\",axis=1)\n",
        "y=data_final2[\"logy\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_xY-1fF6miU"
      },
      "source": [
        "X = x.drop([\"cd_faixa_etaria_1\",\"fator_Ausente\",\"ano_2019\",\"internacao_Ausente\",\"abrangencia_Nacional\",\"in_obstetricia_1\",\"abrangencia_Grupo de munic√≠pios\",\"segmentacao_Ambulatorial e Hospitalar\",\"abrangencia_Grupo de estados\",'ano_2015',\"mes_01\",'fator_Franquia','acomodacao_Individual','fator_Franquia + Co-participa√ß√£o',\"acomodacao_Coletiva\",\"acomodacao_N√£o identificado\",\"acomodacao_N√£o se aplica\",\"acomodacao_N√£o identificado\",\"internacao_Parcial com interna√ß√£o\",\"internacao_Parcial sem interna√ß√£o\",\"cd_faixa_etaria_10\",\"nm_regiao_Norte\"],axis=1)\n",
        "calc_vif(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KXNfizE8SsS"
      },
      "source": [
        "x= x.drop([\"cd_faixa_etaria_1\",\"fator_Ausente\",\"ano_2019\",\"internacao_Ausente\",\"abrangencia_Nacional\",\"in_obstetricia_1\",\"abrangencia_Grupo de munic√≠pios\",\"segmentacao_Ambulatorial e Hospitalar\",\"abrangencia_Grupo de estados\",'ano_2015',\"mes_01\",'fator_Franquia','acomodacao_Individual','fator_Franquia + Co-participa√ß√£o',\"acomodacao_Coletiva\",\"acomodacao_N√£o identificado\",\"acomodacao_N√£o se aplica\",\"acomodacao_N√£o identificado\",\"internacao_Parcial com interna√ß√£o\",\"internacao_Parcial sem interna√ß√£o\",\"cd_faixa_etaria_10\",\"nm_regiao_Norte\"],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCnltdZE90jZ"
      },
      "source": [
        "#testando modelo SVM\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "#Normalizando os dados as variaveis preditoras\n",
        "normalizador=MinMaxScaler(feature_range=(0,1))\n",
        "x_norm=normalizador.fit_transform(x)\n",
        "\n",
        "#Criacao do modelo\n",
        "modelo=SVR()# VALORES DEFEL, KERNEL RBF, GAMMA SOH VALE PARA ALGUNS, C=1, O EPSON=0.1 TEM A REGRESSAO QUE EH O TAMANHO DO CANAL\n",
        "kfold=KFold(n_splits=3)\n",
        "resultado=cross_val_score(modelo,x_norm,y,cv=kfold,n_jobs=-1)\n",
        "print(resultado.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLi-BzqM94iJ"
      },
      "source": [
        "#tunning da SVM\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "#Definindo valores que serao testados na SVR\n",
        "c=np.array([1.0,0.95,1.05,1.1,1.2,1.5,2,0.9,0.8]) # constante de regularizacao, testar maiores e menores que o default, se der extremos, varias mais\n",
        "kernel=[\"linear\",\"poly\",\"rbf\",\"sigmoid\"]\n",
        "polinomio=np.array([2,3,4]) # soh serao usados para kernel polinomio, para  o resto serao ignorados\n",
        "epsilon=np.array([0.1,0.2,0.05,0.03,0.02,0.01,0.005])\n",
        "valores_grid={\"C\":c,\"kernel\":kernel,\"degree\":polinomio,\"epsilon\": epsilon}\n",
        "\n",
        "#Criacao do modelo\n",
        "modelo=SVR()\n",
        "\n",
        "#Criando os grids\n",
        "kfold=KFold(n_splits=3,shuffle=True)# sempre importante e faz toda diferenca\n",
        "gridSVM=GridSearchCV(estimator=modelo,param_grid=valores_grid,cv=kfold,n_jobs=-1)\n",
        "gridSVM.fit(x_norm,y)\n",
        "#Imprimindo melhores parametros\n",
        "print(\"Melhor valor constante de regularizacao: \", gridSVM.best_estimator_.C)\n",
        "print(\"Melhor KERNEL: \", gridSVM.best_estimator_.kernel)\n",
        "print(\"Melhor grau polinomio: \", gridSVM.best_estimator_.degree)\n",
        "print(\"Melhor valor epsilon: \", gridSVM.best_estimator_.epsilon)\n",
        "print(\"R2: \",gridSVM.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0ngHpED-w-a"
      },
      "source": [
        "#Testando regressoes com regularizacoes\n",
        "#Separando em treino e teste\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_treino,x_teste,y_treino,y_teste = train_test_split(x,y, test_size=0.30,random_state=14) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0QPz6G2_PO-"
      },
      "source": [
        "def modeloregressao(a,b,c,d):\n",
        "  from sklearn.linear_model import LinearRegression\n",
        "  from sklearn.linear_model import Ridge\n",
        "  from sklearn.linear_model import Lasso\n",
        "  from sklearn.linear_model import ElasticNet\n",
        "  x_treino=a\n",
        "  y_treino=b\n",
        "  x_teste=c\n",
        "  y_teste=d\n",
        "  reg=LinearRegression()\n",
        "  ridge=Ridge()\n",
        "  lasso=Lasso()\n",
        "  elastic=ElasticNet()\n",
        "  reg.fit(x_treino,y_treino)\n",
        "  ridge.fit(x_treino,y_treino)\n",
        "  lasso.fit(x_treino,y_treino)\n",
        "  elastic.fit(x_treino,y_treino)\n",
        "  resul_reg=reg.score(x_teste, y_teste)\n",
        "  resul_ridge=ridge.score(x_teste, y_teste)\n",
        "  resul_lasso=lasso.score(x_teste, y_teste)\n",
        "  resul_elastic=elastic.score(x_teste, y_teste)\n",
        "  dic_regmodels={'Linear':resul_reg,'Ridge':resul_ridge,'Lasso':resul_lasso,'Elastic':resul_elastic}\n",
        "  melhor_modelo=max(dic_regmodels,key=dic_regmodels.get) # o paramentro get define o criterio do valor maximo, o .get pega os valores do dicionario\n",
        "  print('Regressao Linear:',resul_reg,'Regressao Ridge:',resul_ridge,'Regressao Lasso:',resul_lasso,'Regressao Elastic:',resul_elastic)\n",
        "  print('O melhor modelo foi:',melhor_modelo,'com o valor:',dic_regmodels[melhor_modelo])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_q-_2IG_Rb1"
      },
      "source": [
        "modeloregressao(x_treino,y_treino,x_teste,y_teste)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DZ1xB2M_z9f"
      },
      "source": [
        "#Definindo os valores que serao testados\n",
        "#o RandomizedSearchCV cv vai pegar os melhores  valores das combinacoes abaixo, MAS ALEATORIOS, ELE NAO TESTA TODOS .. ESSA EH A DIFERENCA QUANTO AO GRIDSEARCHCV\n",
        "valores={'alpha':[0.1,0.5,1,2,5,10,25,50,80,90,95,99,100,110,112,115,125,150,200,300,500,750,1000,2000,3000,5000]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuTVOrWN_1Me"
      },
      "source": [
        "#CRIando o modelo\n",
        "#Custo computacional muito alto\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "modelo= Ridge()\n",
        "procura=GridSearchCV(estimator=modelo,param_grid=valores,cv=5)# nao precisamos setra o numero de itracoes pois ele vai testar tudo\n",
        "procura.fit(x,y)\n",
        "# ela usa o kfold padrao, e se for classificacao ja usa o stratified kfold\n",
        "#Imprimindo o resultado\n",
        "print ('Melhor Score:',procura.best_score_)\n",
        "print ('Melhor Alpha:',procura.best_estimator_.alpha)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehGV8LC8AF4u"
      },
      "source": [
        "##Testando com Gradient Boosting\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "#criacao do modelo\n",
        "modelo=GradientBoostingRegressor(n_estimators=500)\n",
        "resultado=cross_val_score(modelo,x,y,cv=3,n_jobs=-1)# -1 utiliza todos os cores do computador\n",
        "print(resultado.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWX4eB8eAK1q"
      },
      "source": [
        "##Tunando Gradient Boosting\n",
        "#Tuning\n",
        "import numpy as np\n",
        "from sklearn.ensemble import GradientBoostingRegressor \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "#Definindo os valores que serao testados em GB\n",
        "valores_grid={\"learning_rate\": np.array([0.9,0.8,0.7,0.6,0.5,0.4,0.3,0.2,0.1,0.15,0.095,0.05,0.06,0.07,0.01,0.001]),\"n_estimators\": np.array([10,20,40,100,200,300,350,400,450,500])}\n",
        "#se a melhor perromance for os extremos, podenso ir refinando os extremos\n",
        "#na teoria, quanto maior o numero de estimadores eh melhor\n",
        "#lembrar de fixar o random o state\n",
        "\n",
        "# geralmente a mesma % que aumento os estimadores eu tenho que reduzir o learning rate\n",
        "#Criacao do modelo\n",
        "modelo=GradientBoostingRegressor()\n",
        "#criando os grids:\n",
        "gridGB=GridSearchCV(estimator=modelo,param_grid=valores_grid,cv=5,n_jobs=-1)\n",
        "gridGB.fit(x,y)\n",
        "\n",
        "#imprimindo melhores parametros\n",
        "print(\"Melhor taxa de aprendizagem: \",gridGB.best_estimator_.learning_rate)\n",
        "print(\"Melhor numero de estimadores: \",gridGB.best_estimator_.n_estimators)\n",
        "print(\"R2: \",gridGB.best_score_)\n",
        "#https://scikit-learn.org/stable/modules/model_evaluation.html#mean-absolute-error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFQogVYZAbp9"
      },
      "source": [
        "#testando arvore de decisao\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV #poderia ser a randomized search cv\n",
        "#from sklearn.metrics import fbeta_score,r2_score\n",
        "\n",
        "#Definindo os valores que serao testados em DecisionTree:\n",
        "minimos_split=np.array([2,3,4,5,6,7]) # quantidade minima de amostra que term que ter pra fazer o split\n",
        "maximo_nivel=np.array([3,4,5,6,7,9,11]) # tamanho da arvore, quantidade maximo de niveis\n",
        "algoritmo=[\"mse\",\"friedman_mse\",\"mae\"] #aqui ele faz a escolha do melhor split( cart, por exemplo- considera o menor erro e minimiza a funcao de custo) mas ele sempre considera media e desvio padrao, soh mud ao metodo de corte\n",
        "valores_grid={\"min_samples_split\":minimos_split,\"max_depth\":maximo_nivel,\"criterion\":algoritmo}\n",
        "\n",
        "#criacao do modelo\n",
        "modelo=DecisionTreeRegressor() #Instancia a funcao\n",
        "\n",
        "#Criando os grids\n",
        "gridDecisionTree=GridSearchCV(estimator=modelo,param_grid=valores_grid,cv=5)# cv=5 numero d efoldos pra fazer o crossvalidation\n",
        "gridDecisionTree=GridSearchCV(estimator=modelo,param_grid=valores_grid,cv=5) # variando o tipo de score neg_mean_absolute_error\n",
        "gridDecisionTree.fit(x,y)\n",
        "\n",
        "#Imprimindo os melhores parametros\n",
        "print(\"Minimo split: \",gridDecisionTree.best_estimator_.min_samples_split)\n",
        "print(\"Maxima Profundidade: \",gridDecisionTree.best_estimator_.max_depth)\n",
        "print(\"Algoritmo Escolhido: \",gridDecisionTree.best_estimator_.criterion)\n",
        "print(\"Coeficiente R2: \",gridDecisionTree.best_score_) # basta ver o score na documentacao"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}